# configs/flowmatch.yaml
stages:
  mode: videos  # (unused here; FM is unconditional on latent videos)

train_dataset:
  name: CINEFlowMatchDataset
  args:
    root: /storage/CINE_data
    split: train
    normalize: qmag
    num_time_samples: 2        # return 2 random T clips per item
    t_choices: [1,3,5,7,9,11]  # odd Ts

val_dataset:
  name: CINEFlowMatchDataset
  args:
    root: /storage/CINE_data
    split: val
    normalize: qmag

dataloader:
  train_batch_size: 1     # each item yields a list of clips; we flatten across the batch
  val_batch_size: 1
  num_workers: 8
  pin_memory: false
  shuffle: true

# Frozen VAE (for latent space)
vae:
  import_path: CardiacVAE.model.vae
  class_name: CardiacVAE
  args:
    in_channels: 2
    z_dim: 16
    dim: 128
    dim_mult: [1, 2, 4]
    num_res_blocks: 2
    attn_scales: []
    dropout: 0.0

# FM transformer
model:
  import_path: models.latent_fm_transformer
  class_name: LatentFlowMatchTransformer
  args:
    latent_channels: 16
    hidden_size: 768
    depth: 16
    heads: 12
    mlp_ratio: 4.0
    patch_size: [1, 1, 1]   # latent tokens = n'*H'*W'

optim:
  lr: 0.0002
  betas: [0.9, 0.99]
  weight_decay: 0.01
  grad_clip: 1.0
  total_steps: 100000
  ema_decay: 0.999

train:
  use_posterior_sample: false  # set true to sample z ~ N(mu, Sigma) instead of mu

validation:
  patch_h: 80
  patch_w: 80

sampler:
  num_steps: 18
  variant: bh1

logging:
  project: cardiac-lfm             # NEW
  run_name: wan_fm_videos          # NEW
  log_every_steps: 50
  val_every_steps: 2000
  save_every_steps: 5000
  val_num_batches: 8               # NEW (how many batches to use for val MSE)
  out_dir: /storage/matt_models/latent_fm
  wandb_dir: /storage/matt_models/wandb   # NEW (optional)
  wandb_cache_dir: /storage/matt_models/wandbcache  # NEW (optional)

